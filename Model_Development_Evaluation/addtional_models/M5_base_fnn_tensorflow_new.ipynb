{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lianfeng/Document/species_richness_sdm/venv/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upgrade in command line for specific interpreter\n",
    "\n",
    "import sys\n",
    "sys.executable\n",
    "# /Users/lianfeng/Document/species_richness_sdm/venv/bin/pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1rRo8oNqZ-Rj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import datetime\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use some functions from tensorflow_docs\n",
    "!pip install -q git+https://github.com/tensorflow/docs\n",
    "    \n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_72b0LCNbjx"
   },
   "source": [
    "#### Get the data from PG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9kxxgzvzlyz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15310, 22)\n",
      "(13503, 22)\n"
     ]
    }
   ],
   "source": [
    "localhost = {'user': 'postgres', 'password': 'postgres', 'host': 'localhost', 'port': 5432, 'db': 'fiadb'}\n",
    "params = 'postgresql://{0}:{1}@{2}:{3}/{4}'\n",
    "engine = create_engine(params.format(localhost['user'], localhost['password'], localhost['host'], localhost['port'], localhost['db']))\n",
    "# geom_sql = \"\"\"select distinct grid_id, grid_geom from fs_fiadb.pergrid\"\"\"\n",
    "pergrid_base = \"\"\"select distinct * from predictor.pergrid_base\"\"\"\n",
    "pergrid_base_df = pd.read_sql(pergrid_base, engine)\n",
    "print(pergrid_base_df.shape)\n",
    "pergrid_base_df_na_remove = pergrid_base_df.dropna()\n",
    "print(pergrid_base_df_na_remove.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pergrid_base_encoded=pd.get_dummies(pergrid_base_df_na_remove, columns=[\"hydrogroup\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['grid_id', 'aet', 'ai', 'art', 'ewd', 'fa', 'map', 'mat', 'mpdq',\n",
       "       'mtcq', 'pet', 'psn', 'ra', 'rmap', 'rmat', 'tsn', 'mfdf', 'alt',\n",
       "       'mtwq', 'wkb_geometry', 'tsr', 'hydrogroup_A', 'hydrogroup_A/D',\n",
       "       'hydrogroup_B', 'hydrogroup_B/D', 'hydrogroup_C', 'hydrogroup_C/D',\n",
       "       'hydrogroup_D'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pergrid_base_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_var= ['aet', 'ai', 'art', 'ewd', 'fa', 'map', 'mat', 'mpdq',\n",
    "       'mtcq', 'pet', 'psn', 'ra', 'rmap', 'rmat', 'tsn', 'mfdf', 'alt',\n",
    "       'mtwq','hydrogroup_A', 'hydrogroup_A/D',\n",
    "       'hydrogroup_B', 'hydrogroup_B/D', 'hydrogroup_C', 'hydrogroup_C/D',\n",
    "       'hydrogroup_D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pergrid_base_encoded[pred_var]\n",
    "\n",
    "# standarize predictors\n",
    "ss = StandardScaler(with_mean=False, with_std=False)\n",
    "X_std = ss.fit_transform(X.values)\n",
    "\n",
    "Xstd=pd.DataFrame(data=X_std[0:,0:],\n",
    "                index=X.index,\n",
    "                columns=pred_var)\n",
    "y_true = pergrid_base_encoded['tsr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xstd, y_true, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5438     28.0\n",
       "8405     17.0\n",
       "2757     34.0\n",
       "3253     20.0\n",
       "5835      9.0\n",
       "         ... \n",
       "4618      1.0\n",
       "3176     33.0\n",
       "8452     37.0\n",
       "9369     23.0\n",
       "13600    23.0\n",
       "Name: tsr, Length: 2701, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['aet', 'ai', 'art', 'ewd', 'fa', 'map', 'mat', 'mpdq', 'mtcq', 'pet',\n",
       "       'psn', 'ra', 'rmap', 'rmat', 'tsn', 'mfdf', 'alt', 'mtwq',\n",
       "       'hydrogroup_A', 'hydrogroup_A/D', 'hydrogroup_B', 'hydrogroup_B/D',\n",
       "       'hydrogroup_C', 'hydrogroup_C/D', 'hydrogroup_D'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SWtkIjhrZwa"
   },
   "source": [
    "### Build the model\n",
    "`Sequential` model with two densely connected hidden layers, and an output layer that returns a single, continuous value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When training with Keras's Model.fit(), adding the tf.keras.callbacks.TensorBoard callback ensures that logs are created and stored. Additionally, enable histogram computation every epoch with histogram_freq=1 (this is off by default)\n",
    "Place the logs in a timestamped subdirectory to allow easy selection of different training runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0-qWCsh6DlyH"
   },
   "source": [
    "### Train the model and tune hyperparameters\n",
    "\n",
    "Train the model for 1000 epochs, and record the training and validation accuracy in the `history` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use an EarlyStopping callback that tests a training condition for every epoch. If a set amount of epochs elapses without showing improvement, then automatically stop the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([500, 1000, 2000, 3000]))\n",
    "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2,)) # units to drop rate\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam']))\n",
    "METRIC_ACCURACY = 'mean_absolute_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard\n",
    "\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "log_dir = \"logs/M5_base_fnn_tensorflow/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "def train_test_model(hparams):\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(hparams[HP_NUM_UNITS], activation='relu', input_shape=[X_train.shape[1]]),\n",
    "    layers.Dense(hparams[HP_NUM_UNITS], activation='relu'),\n",
    "    layers.Dense(hparams[HP_NUM_UNITS], activation='relu'),\n",
    "#     layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    layers.Dense(1, activation='linear')\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='mae',\n",
    "      metrics=['mean_absolute_error']\n",
    "  )\n",
    "\n",
    "  model.fit(x=X_train, \n",
    "            y=y_train, \n",
    "            epochs=EPOCHS, \n",
    "            validation_split = 0.2, \n",
    "            verbose=0, \n",
    "            callbacks=[tfdocs.modeling.EpochDots(), early_stop, tensorboard_callback])\n",
    "  _, mean_absolute_error = model.evaluate(X_test, y_test)\n",
    "\n",
    "  return mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    mean_absolute_error = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, mean_absolute_error, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 500, 'optimizer': 'adam'}\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:6661.1744,  mean_absolute_error:6661.1797,  val_loss:632.2912,  val_mean_absolute_error:632.2911,  \n",
      "....................WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "2701/2701 [==============================] - 0s 40us/sample - loss: 11.5361 - mean_absolute_error: 11.5360\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 500, 'optimizer': 'adam'}\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:7023.6753,  mean_absolute_error:7023.6748,  val_loss:17.1269,  val_mean_absolute_error:17.1269,  \n",
      ".....................WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "2701/2701 [==============================] - 0s 50us/sample - loss: 11.5076 - mean_absolute_error: 11.5076\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 1000, 'optimizer': 'adam'}\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:7282.5054,  mean_absolute_error:7282.5039,  val_loss:16.8456,  val_mean_absolute_error:16.8456,  \n",
      "..................WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "2701/2701 [==============================] - 0s 82us/sample - loss: 11.6173 - mean_absolute_error: 11.6173\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 1000, 'optimizer': 'adam'}\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:7173.1149,  mean_absolute_error:7173.1177,  val_loss:15.0773,  val_mean_absolute_error:15.0773,  \n",
      ".......................WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "2701/2701 [==============================] - 0s 83us/sample - loss: 11.5668 - mean_absolute_error: 11.5668\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 2000, 'optimizer': 'adam'}\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:9630.0963,  mean_absolute_error:9630.1016,  val_loss:14.5656,  val_mean_absolute_error:14.5656,  \n",
      "..........................WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "2701/2701 [==============================] - 1s 245us/sample - loss: 11.9483 - mean_absolute_error: 11.9483\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 2000, 'optimizer': 'adam'}\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:8350.1883,  mean_absolute_error:8350.1807,  val_loss:15.3428,  val_mean_absolute_error:15.3428,  \n",
      "......................WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "2701/2701 [==============================] - 1s 307us/sample - loss: 14.0599 - mean_absolute_error: 14.0599\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 3000, 'optimizer': 'adam'}\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:10795.7537,  mean_absolute_error:10795.7559,  val_loss:14.7478,  val_mean_absolute_error:14.7478,  \n",
      "..........................................WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "2701/2701 [==============================] - 1s 353us/sample - loss: 11.6608 - mean_absolute_error: 11.6608\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 3000, 'optimizer': 'adam'}\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:10330.7394,  mean_absolute_error:10330.7334,  val_loss:776.1997,  val_mean_absolute_error:776.1998,  \n",
      "......................WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "2701/2701 [==============================] - 1s 380us/sample - loss: 11.4924 - mean_absolute_error: 11.4924\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "        hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "#           HP_DROPOUT: dropout_rate,\n",
    "          HP_OPTIMIZER: optimizer,\n",
    "        }\n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('logs/M5_base_fnn_tensorflow/' + run_name, hparams)\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 48660), started 1:50:05 ago. (Use '!kill 48660' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2af2fefbd80e0fe5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2af2fefbd80e0fe5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ft603OzXuEZC"
   },
   "source": [
    "### Make predictions\n",
    "\n",
    "Finally, predict TSR values using data in the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(hparams[HP_NUM_UNITS], activation='relu', input_shape=[len(train_dataset.keys())]),\n",
    "    layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    layers.Dense(hparams[HP_NUM_UNITS], activation='relu'),\n",
    "    layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    layers.Dense(hparams[HP_NUM_UNITS], activation='relu'),\n",
    "    layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    layers.Dense(1, activation='linear')\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, loss:5.3133,  mean_absolute_error:5.3133,  val_loss:4.2593,  val_mean_absolute_error:4.2593,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:3.3962,  mean_absolute_error:3.3962,  val_loss:3.3564,  val_mean_absolute_error:3.3564,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:3.3190,  mean_absolute_error:3.3190,  val_loss:3.3038,  val_mean_absolute_error:3.3038,  \n",
      ".............."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15635d0f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "best_model.compile(\n",
    "    optimizer='adagrad',\n",
    "    loss='mae',\n",
    "    metrics=['mean_absolute_error']\n",
    ")\n",
    "\n",
    "best_model.fit(x=normed_train_data, \n",
    "        y=train_labels, \n",
    "        epochs=EPOCHS, \n",
    "        validation_split = 0.2, \n",
    "        verbose=0, \n",
    "        callbacks=[tfdocs.modeling.EpochDots(), early_stop, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xe7RXH3N3CWU"
   },
   "outputs": [],
   "source": [
    "test_predictions = best_model.predict(normed_test_data).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19wyogbOSU5t"
   },
   "source": [
    "It looks like our model predicts reasonably well. Let's take a look at the error distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-OHX4DiXd8x"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "error = test_predictions - test_labels\n",
    "plt.hist(error, bins = 25)\n",
    "plt.xlabel(\"Prediction Error [TSR]\")\n",
    "_ = plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make TSR predictions using the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = model.predict(normed_test_data).flatten()\n",
    "y_pred = best_model.predict(normed_dataset).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest TSR predictions to PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pergrid_all_predicted = pd.DataFrame(\n",
    "    {'grid_id': grid_id,\n",
    "     'tsr': full_labels,\n",
    "     'tsr_predicted': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pergrid_all_predicted.to_sql(name='m5_base_fnn_tensorflow', con=engine, schema='predictor', if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_geom = \"\"\"\n",
    "alter table predictor.m5_base_fnn_tensorflow add column if not exists wkb_geometry geometry(Polygon,4269);\n",
    "update predictor.m5_base_fnn_tensorflow A SET wkb_geometry = B.wkb_geometry\n",
    "FROM predictor.pergrid_base B\n",
    "WHERE A.grid_id = B.grid_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x14e093668>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = engine.connect()\n",
    "connection.execute(update_geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_residual = \"\"\"\n",
    "alter table predictor.m5_base_fnn_tensorflow add column residual double precision;\n",
    "update predictor.m5_base_fnn_tensorflow set residual = (tsr_predicted-tsr);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x14e3ab828>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = engine.connect()\n",
    "connection.execute(update_residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "regression.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
